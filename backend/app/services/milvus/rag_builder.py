"""
RAG ç´¢å¼•æ„å»ºå™¨

åŠŸèƒ½ï¼š
1. æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„åŠ è½½ï¼ˆPDFã€Markdownã€TXTã€CSVã€HTMLã€DOCX ç­‰ï¼‰
2. æ™ºèƒ½æ–‡æ¡£åˆ†å‰²
3. å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° Milvus
4. æä¾›å®Œæ•´çš„ RAG ç´¢å¼•æ„å»ºæµç¨‹

è¯´æ˜ï¼š
- æœ¬æ¨¡å—ä¸“æ³¨äº LangChain åŸç”Ÿæ–‡æ¡£åŠ è½½ï¼ˆé€‚ç”¨äºçº¯æ–‡æœ¬ RAGï¼‰
- å¦‚éœ€å›¾æ–‡æ··åˆè§£æï¼Œè¯·ä½¿ç”¨ app.services.document_parser
"""

from pathlib import Path
from typing import List, Optional

from langchain_community.document_loaders import (
    CSVLoader,
    PyPDFLoader,
    TextLoader,
    UnstructuredHTMLLoader,
    UnstructuredWordDocumentLoader,
)
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

from app.config import settings
from app.services.milvus.client import MilvusClient

# ==================== æ”¯æŒçš„æ–‡ä»¶ç±»å‹æ˜ å°„ ====================

LOADER_MAPPING = {
    ".pdf": PyPDFLoader,
    ".md": TextLoader,
    ".txt": TextLoader,
    ".log": TextLoader,
    ".csv": CSVLoader,
    ".html": UnstructuredHTMLLoader,
    ".htm": UnstructuredHTMLLoader,
    ".docx": UnstructuredWordDocumentLoader,
    ".doc": UnstructuredWordDocumentLoader,
}

SUPPORTED_EXTENSIONS = list(LOADER_MAPPING.keys())


class RAGBuilder:
    """
    RAG ç´¢å¼•æ„å»ºç±»

    èŒè´£ï¼š
    - åŠ è½½å„ç§æ ¼å¼çš„æ–‡æ¡£
    - æ™ºèƒ½æ–‡æ¡£åˆ†å‰²
    - æ„å»º RAG ç´¢å¼•
    """

    def __init__(
        self,
        chunk_size: Optional[int] = None,
        chunk_overlap: Optional[int] = None,
    ):
        """
        åˆå§‹åŒ–æ„å»ºå™¨

        Args:
            chunk_size: åˆ†å—å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            chunk_overlap: åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        """
        self.chunk_size = chunk_size or settings.DEFAULT_MAX_CHUNK_SIZE
        self.chunk_overlap = chunk_overlap or settings.DEFAULT_CHUNK_OVERLAP

    # ==================== æ–‡æ¡£åŠ è½½ ====================

    def get_loader(self, file_path: str):
        """
        æ ¹æ®æ–‡ä»¶è·¯å¾„è·å–åˆé€‚çš„ loader å®ä¾‹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Loader å®ä¾‹

        Raises:
            ValueError: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        """
        path = Path(file_path)
        ext = path.suffix.lower()

        if ext not in LOADER_MAPPING:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}ï¼Œæ”¯æŒçš„ç±»å‹: {SUPPORTED_EXTENSIONS}"
            )

        loader_cls = LOADER_MAPPING[ext]

        # TextLoader éœ€è¦æŒ‡å®šç¼–ç 
        if loader_cls == TextLoader:
            return loader_cls(str(path), encoding="utf-8")

        return loader_cls(str(path))

    def load_file(self, file_path: str) -> List[Document]:
        """åŠ è½½å•ä¸ªæ–‡ä»¶"""
        try:
            loader = self.get_loader(file_path)
            return loader.load()
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return []

    def load_directory(
        self,
        dir_path: str,
        extensions: Optional[List[str]] = None,
        recursive: bool = True,
    ) -> List[Document]:
        """
        åŠ è½½ç›®å½•å†…çš„æ‰€æœ‰å¯è¯†åˆ«æ–‡ä»¶

        Args:
            dir_path: ç›®å½•è·¯å¾„
            extensions: è¦åŠ è½½çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼ˆé»˜è®¤åŠ è½½æ‰€æœ‰æ”¯æŒçš„ç±»å‹ï¼‰
            recursive: æ˜¯å¦é€’å½’éå†å­ç›®å½•

        Returns:
            List[Document]: åŠ è½½çš„æ–‡æ¡£åˆ—è¡¨
        """
        root_path = Path(dir_path)

        if not root_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return []

        target_extensions = extensions or SUPPORTED_EXTENSIONS
        target_extensions = [ext.lower() for ext in target_extensions]

        docs = []
        pattern = "**/*" if recursive else "*"

        for file_path in root_path.glob(pattern):
            if file_path.is_file() and file_path.suffix.lower() in target_extensions:
                file_docs = self.load_file(str(file_path))
                if file_docs:
                    docs.extend(file_docs)
                    print(f"âœ“ å·²åŠ è½½: {file_path.name} ({len(file_docs)} ä¸ªæ–‡æ¡£)")

        print(f"ğŸ“Š å…±åŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£")
        return docs

    # ==================== æ–‡æ¡£åˆ†å‰² ====================

    def split_documents(
        self,
        docs: List[Document],
        chunk_size: Optional[int] = None,
        chunk_overlap: Optional[int] = None,
        use_tiktoken: bool = False,
    ) -> List[Document]:
        """
        åˆ†å‰²æ–‡æ¡£

        Args:
            docs: æ–‡æ¡£åˆ—è¡¨
            chunk_size: åˆ†å—å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨å®ä¾‹é…ç½®ï¼‰
            chunk_overlap: åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨å®ä¾‹é…ç½®ï¼‰
            use_tiktoken: æ˜¯å¦ä½¿ç”¨ tiktoken ç¼–ç å™¨

        Returns:
            List[Document]: åˆ†å‰²åçš„æ–‡æ¡£ç‰‡æ®µ
        """
        size = chunk_size or self.chunk_size
        overlap = chunk_overlap or self.chunk_overlap

        if use_tiktoken:
            text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
                chunk_size=size,
                chunk_overlap=overlap,
            )
        else:
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=size,
                chunk_overlap=overlap,
                length_function=len,
                is_separator_regex=False,
            )

        return text_splitter.split_documents(docs)

    # ==================== RAG ç´¢å¼•æ„å»º ====================

    def build_index(
        self,
        data_dir: str,
        db_name: Optional[str] = None,
        collection_name: Optional[str] = None,
        chunk_size: Optional[int] = None,
        chunk_overlap: Optional[int] = None,
        drop_old: bool = False,
        verbose: bool = True,
    ) -> Optional[MilvusClient]:
        """
        æ„å»º RAG ç´¢å¼•ï¼šåŠ è½½æ–‡æ¡£ -> åˆ†å‰² -> å‘é‡åŒ– -> å­˜å‚¨åˆ° Milvus

        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            db_name: Milvus æ•°æ®åº“åç§°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            collection_name: é›†åˆåç§°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            chunk_size: æ–‡æ¡£åˆ†å—å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨å®ä¾‹é…ç½®ï¼‰
            chunk_overlap: åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤ä½¿ç”¨å®ä¾‹é…ç½®ï¼‰
            drop_old: æ˜¯å¦åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—

        Returns:
            MilvusClient: åˆå§‹åŒ–å®Œæˆçš„ Milvus å®¢æˆ·ç«¯ï¼Œå¤±è´¥è¿”å› None
        """
        print("=" * 60)
        print("å¼€å§‹æ„å»º RAG ç´¢å¼•")
        print("=" * 60)

        # 1. åˆå§‹åŒ– Milvus
        print("\n1. åˆå§‹åŒ– Milvus å‘é‡å­˜å‚¨")
        milvus = MilvusClient(
            db_name=db_name or settings.MILVUS_DB_NAME,
            collection_name=collection_name or settings.MILVUS_COLLECTION_NAME,
            drop_old=drop_old,
            verbose=verbose,
        )

        if not milvus.initialize():
            print("âŒ Milvus åˆå§‹åŒ–å¤±è´¥")
            return None

        # 2. åŠ è½½æ–‡æ¡£
        print(f"\n2. åŠ è½½æ–‡æ¡£ç›®å½•: {data_dir}")
        docs = self.load_directory(data_dir)
        if not docs:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
            return None
        print(f"âœ… æˆåŠŸåŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£")

        # 3. åˆ†å‰²æ–‡æ¡£
        size = chunk_size or self.chunk_size
        overlap = chunk_overlap or self.chunk_overlap
        print(f"\n3. åˆ†å‰²æ–‡æ¡£ (chunk_size={size}, overlap={overlap})")
        doc_splits = self.split_documents(docs, chunk_size=size, chunk_overlap=overlap)
        print(f"âœ… åˆ†å‰²æˆ {len(doc_splits)} ä¸ªç‰‡æ®µ")

        # 4. æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
        print("\n4. æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨")
        if not milvus.add_documents(doc_splits):
            print("âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥")
            return None

        print("\n" + "=" * 60)
        print("ğŸ‰ RAG ç´¢å¼•æ„å»ºå®Œæˆ!")
        print("=" * 60)

        return milvus

    def load_and_split(
        self,
        data_dir: str,
        chunk_size: Optional[int] = None,
        chunk_overlap: Optional[int] = None,
    ) -> List[Document]:
        """
        åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£ï¼ˆä¸å­˜å‚¨åˆ° Milvusï¼‰

        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            chunk_size: æ–‡æ¡£åˆ†å—å¤§å°
            chunk_overlap: åˆ†å—é‡å å¤§å°

        Returns:
            List[Document]: åˆ†å‰²åçš„æ–‡æ¡£ç‰‡æ®µåˆ—è¡¨
        """
        docs = self.load_directory(data_dir)
        if not docs:
            return []

        return self.split_documents(
            docs,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
        )
